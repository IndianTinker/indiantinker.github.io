---
layout: post
title: FAND - shareable haptic foot interface device
image: https://i.imgur.com/Pr2hwhl.png
location:  IDC IIT Bombay India
tags:
- design
- select 
- note
field: design research<br>interaction techniques
---

>The project research was presented at IEEE SeGAH 2018, Vienna in a paper published as <a href="https://ieeexplore.ieee.org/abstract/document/8401321"> Gupta,R. &amp; Dalvi, G (2018, May). FAND: A shareable haptic foot interface device. </a> .

FAND (Foot associated neural device) is a haptic interface device that allows users to operate a computer (or certain applications) using all four limbs. The device uses user trained motion gestures that are bound to actions on a compatible application. One may be surprised to know that foot is only 10% less accurate than the hand. The interaction model developed in the project divides a task in a primary action and a secondary action. The primary, high priority and accurate task is handled by the hand, while the secondary tasks are handled by the foot. Devices like these are useful in times when most of our interaction are performed by the hands. This has increased the physiological load on hands. The possible applications are in applications like creative apps, Walking in Place (WIP) interactions in VR, and gaming. I evaluated the device by comparing it with a novel hand interaction device. In the study it was found that the foot device offers comparable learning and may be considered as a possible modality. 

![Imgur](https://i.imgur.com/Vxondpp.png)

The video demonstrating the concept is shown below:

<iframe width="560" height="315" src="https://www.youtube.com/embed/ByvJjlRdu9M" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>


<h4>User Persona</h4>
![Imgur](https://i.imgur.com/N2sgquh.png)
![Imgur](https://i.imgur.com/W7SAryx.png)
![Imgur](https://i.imgur.com/v5pzbJk.png)


Several explorations and ideation were done in light of previous works and user studies conducted. The final report is be available [here](https://drive.google.com/file/d/1CH4XgkzvzWaVjZDxJgtrWlma4ZTeb1hH/view?usp=sharing). This report was made in Google Docs. ProTip: Do not use google docs of large documents. I never use google docs for more than 10 pages. 

The post only covers some parts of a rather long design process (~ 6 months). I tried several techniques to understand the design of gesture systems. I did a [Wobbrock](https://faculty.washington.edu/wobbrock/) style study to derive the guess-ability of certain guestures. The users were should de-contextualized prompts to certain interactions and were asked to come up with responses. I would encourage reading the paper by Wobbrock et al.

The prompts were like the below for zoom:
![Imgur](https://i.imgur.com/AfqMZQs.gif)

Based on my **user set** the gesture set was as follows. One can obviously spot the similarities between these interactions and interactions performed by hands. Many users agreed that they performed the most natural interactions they could think of.
![Imgur](https://i.imgur.com/P87F5J1.png)

The gesture set was used with the following *design requirements* to come up with several concepts.
![Imgur](https://i.imgur.com/1VtQrY4.png)

The most dominant concept was of a shareable foot accessory that was prototyped. The process of prototyping was done separately for both form and function.

Form variations considering sharing and multiple foot types
![Imgur](https://i.imgur.com/OuFxiwN.png)
![Imgur](https://i.imgur.com/fokP6Um.png)

Functional Prototype made using Arduino running thresholding and a simple wave pattern recognizer algorithm on the data of a MPU6050 gyro sensor

![Imgur](https://i.imgur.com/TGOhCAQ.png)

The prototype was tested with users using a true experiment design. The results showed that F(4,20) at p<0.05 the device when compared to a new type of hand device like trackpoint has statistical significance (repeated measures ANOVA).Hence, both devices have similar learnability.

Cheers,

Rohit
